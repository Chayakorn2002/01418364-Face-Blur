{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import glob as gb\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from joblib import  load\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training dataset\n",
    "# horizontal_flip = True\n",
    "#   - Randomly flip images horizontally\n",
    "# rescale = 1 / 255.0\n",
    "#   - Rescale the image by 1 / 255.0\n",
    "# flow_from_directory: \n",
    "\n",
    "train_dir = 'images/train'\n",
    "Train_Data = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    horizontal_flip = True,\n",
    "    rescale = 1 / 255.0,\n",
    ").flow_from_directory(\n",
    "    train_dir, \n",
    "    batch_size = 16, \n",
    "    subset = \"training\", \n",
    "    target_size = (224, 224), # resize image to `224 x 224`\n",
    "    shuffle = False \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 16 images from the training dataset\n",
    "classes = list(Train_Data.class_indices.keys()) \n",
    "plt.figure(figsize=(30, 30))\n",
    "\n",
    "# Iterate over batches of images and labels in the training dataset\n",
    "for X_batch, y_batch in Train_Data: \n",
    "    # Iterate over the first 16 samples in the batch\n",
    "    for i in range(0, 16):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(X_batch[i])\n",
    "        plt.title(classes[np.where(y_batch[i] == 1)[0][0]])\n",
    "    plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifyFaceWithDeepface(image_path):\n",
    "    dir_path = 'images/euclidean'\n",
    "    contents = os.listdir(dir_path)\n",
    "    verified_list = {}\n",
    "    \n",
    "    for item in contents:\n",
    "        file_path = os.path.join(dir_path, item)\n",
    "        if os.path.exists(file_path):        \n",
    "            verifying = DeepFace.verify(image_path, file_path, enforce_detection=False)\n",
    "            if verifying['verified']:\n",
    "                if item not in verified_list:\n",
    "                    verified_list[item] = [0, 0]  # Initialize the list with two values\n",
    "                verified_list[item][0] = 1 - verifying['distance']\n",
    "                # print(verifying['facial_areas'])\n",
    "                verified_list[item][1] = verifying['facial_areas']['img1']\n",
    "                \n",
    "    if len(verified_list) > 0:\n",
    "        max_accuracy_class = max(verified_list, key=lambda k: verified_list[k][0])\n",
    "        max_accuracy = verified_list[max_accuracy_class][0]\n",
    "        position = verified_list[max_accuracy_class][1]\n",
    "        \n",
    "        class_name = max_accuracy_class.split('.')[0]\n",
    "        # print(class_name, max_accuracy, position)\n",
    "        return class_name, max_accuracy, position\n",
    "    else:\n",
    "        accuracy = verifying['distance']\n",
    "        position = verifying['facial_areas']['img1']\n",
    "        return 'unidentify', accuracy, position    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Detect Face\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Define the start time\n",
    "start_time = time.time()\n",
    "\n",
    "mtcnn = MTCNN(\n",
    "    image_size=160,  # The size of the image : 160 x 160\n",
    "    margin=14,  # Margin around the bounding box\n",
    "    min_face_size=20,  # Minimum face size\n",
    "    device='cpu',\n",
    "    post_process=False\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture('videos/2.mov')\n",
    "size = (1600, 1200)  # Size of the frame\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, size[1])  # height of the frame\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, size[0])  # width of the frame\n",
    "\n",
    "result_video = cv2.VideoWriter(\n",
    "    'detecting-face.avi', # Name of the video file\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "    30,  # Frames per second\n",
    "    size,  # Size of the frame\n",
    ")\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX  # Font style\n",
    "fontScale = 1  # Font scale\n",
    "color = (255, 0, 0)  # Font color\n",
    "thickness = 2  # Font thickness\n",
    "\n",
    "# Read until video is completed\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Capture frame-by-frame\n",
    "    if not ret:  # If the frame is not read then break the loop\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (1600, 1200), interpolation=cv2.INTER_CUBIC)  # Resize the frame to 1600 x 1200\n",
    "\n",
    "    boxes, probs = mtcnn.detect(frame)  # Detect faces in the frame: boxes and probabilities\n",
    "\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            roi = frame[y1:y2, x1:x2]  # Region of interest: face\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)  # Draw a rectangle around the face\n",
    "\n",
    "    result_video.write(frame)  # Write the frame to the video file\n",
    "    cv2.imshow('frame', frame)  # Display the frame\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):  # If 'q' is pressed then break the loop\n",
    "        break\n",
    "\n",
    "    # Check if more than 1 minute has elapsed\n",
    "    if time.time() - start_time > 60:\n",
    "        break\n",
    "\n",
    "cap.release()  # Release the video capture object\n",
    "result_video.release()  # Release the video writer object\n",
    "cv2.destroyAllWindows()  # Close all the frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect faces with MTCNN and recognize them with DeepFace\n",
    "# With ROI buffered\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Define the start time\n",
    "start_time = time.time()\n",
    "\n",
    "mtcnn = MTCNN(\n",
    "    image_size=160,  # The size of the image : 160 x 160\n",
    "    margin=14,  # Margin around the bounding box\n",
    "    min_face_size=20,  # Minimum face size\n",
    "    device='cpu',\n",
    "    post_process=False\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture('videos/1.mov')\n",
    "size = (1600, 1200)  # Size of the frame\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, size[1])  # height of the frame\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, size[0])  # width of the frame\n",
    "\n",
    "result_video = cv2.VideoWriter(\n",
    "    'recognizing_face.avi', # Name of the video file\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'), # Codec\n",
    "    30, # Frames per second\n",
    "    size, # Size of the frame\n",
    ")\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX  # Font style\n",
    "fontScale = 1 # Font scale\n",
    "color = (255, 0, 0) # Font color\n",
    "thickness = 2  # Font thickness\n",
    "frame_count = 0\n",
    "\n",
    "frame_skip_count = 0\n",
    "frame_skip_interval = 20\n",
    "\n",
    "buffer_path = 'buffer/roi/'\n",
    "\n",
    "# Read until video is completed\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Capture frame-by-frame\n",
    "    frame_count += 1\n",
    "    frame_skip_count += 1\n",
    "    \n",
    "    if frame_skip_count < frame_skip_interval:\n",
    "        continue\n",
    "    else:\n",
    "        frame_skip_count = 0\n",
    "    \n",
    "    if not ret:  # If the frame is not read then break the loop\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame, (1600, 1200), interpolation=cv2.INTER_CUBIC)  # Resize the frame to 1600 x 1200\n",
    "\n",
    "    boxes, probs = mtcnn.detect(frame)  # Detect faces in the frame: boxes and probabilities\n",
    "\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            roi = frame[y1:y2, x1:x2]  # Region of interest: face\n",
    "\n",
    "            # Check if ROI dimensions are valid\n",
    "            if roi.shape[0] < 1 or roi.shape[1] < 1:  \n",
    "                continue\n",
    "            \n",
    "            # Save the ROI to a file\n",
    "            cv2.imwrite(f'{buffer_path}{frame_count}.png', roi) \n",
    "            face_class, accuracy, position = verifyFaceWithDeepface('roi.png')\n",
    "            \n",
    "            if face_class == 'unidentify':\n",
    "                blur_roi = cv2.GaussianBlur(roi, (99, 99), 30)\n",
    "                frame[y1:y2, x1:x2] = blur_roi\n",
    "            \n",
    "            cv2.putText(frame, face_class, (x1-5, y1-5), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "            cv2.putText(frame, str(np.round(accuracy, 2)), (x2, y2-10), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)  # Draw a rectangle around the face\n",
    "            \n",
    "    result_video.write(frame)  # Write the frame to the video file\n",
    "    cv2.imshow('frame', frame)  # Display the frame\n",
    "\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):  # If 'q' is pressed then break the loop\n",
    "        break\n",
    "\n",
    "    # Check if more than 1 minute has elapsed\n",
    "    # if time.time() - start_time > 60:\n",
    "    #     break\n",
    "print(frame_count)\n",
    "cap.release()  # Release the video capture object\n",
    "result_video.release()  # Release the video writer object\n",
    "cv2.destroyAllWindows()  # Close all the frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detect faces with MTCNN and recognize them with DeepFace\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Define the start time\n",
    "start_time = time.time()\n",
    "\n",
    "mtcnn = MTCNN(\n",
    "    image_size=160,  # The size of the image : 160 x 160\n",
    "    margin=14,  # Margin around the bounding box\n",
    "    min_face_size=20,  # Minimum face size\n",
    "    device='cpu',\n",
    "    post_process=False\n",
    ")\n",
    "\n",
    "video_name = input('Enter the name of the video file: ')\n",
    "\n",
    "cap = cv2.VideoCapture(f'videos/{video_name}')\n",
    "size = (1600, 1200)  # Size of the frame\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, size[1])  # height of the frame\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, size[0])  # width of the frame\n",
    "\n",
    "result_video = cv2.VideoWriter(\n",
    "    'recognizing_face.avi', # Name of the video file\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'), # Codec\n",
    "    10, # Frames per second\n",
    "    size, # Size of the frame\n",
    ")\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX  # Font style\n",
    "fontScale = 1 # Font scale\n",
    "color = (255, 0, 0) # Font color\n",
    "thickness = 2  # Font thickness\n",
    "frame_count = 0\n",
    "\n",
    "frame_skip_count = 0\n",
    "frame_skip_interval = 20\n",
    "\n",
    "# Read until video is completed\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Capture frame-by-frame\n",
    "    frame_count += 1\n",
    "    frame_skip_count += 1\n",
    "    \n",
    "    if frame_skip_count < frame_skip_interval:\n",
    "        continue\n",
    "    else:\n",
    "        frame_skip_count = 0\n",
    "    \n",
    "    if not ret:  # If the frame is not read then break the loop\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame, (1600, 1200), interpolation=cv2.INTER_CUBIC)  # Resize the frame to 1600 x 1200\n",
    "\n",
    "    boxes, probs = mtcnn.detect(frame)  # Detect faces in the frame: boxes and probabilities\n",
    "\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            roi = frame[y1:y2, x1:x2]  # Region of interest: face\n",
    "\n",
    "            # Check if ROI dimensions are valid\n",
    "            if roi.shape[0] < 1 or roi.shape[1] < 1:  \n",
    "                continue\n",
    "            \n",
    "            # Save the ROI to a file\n",
    "            cv2.imwrite('roi.png', roi)\n",
    "            face_class, accuracy, position = verifyFaceWithDeepface('roi.png')\n",
    "            \n",
    "            if face_class == 'unidentify':\n",
    "                blur_roi = cv2.GaussianBlur(roi, (99, 99), 30)\n",
    "                frame[y1:y2, x1:x2] = blur_roi\n",
    "            \n",
    "            cv2.putText(frame, face_class, (x1-5, y1-5), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "            cv2.putText(frame, str(np.round(accuracy, 2)), (x2, y2-10), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)  # Draw a rectangle around the face\n",
    "            \n",
    "    result_video.write(frame)  # Write the frame to the video file\n",
    "    cv2.imshow('frame', frame)  # Display the frame\n",
    "\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):  # If 'q' is pressed then break the loop\n",
    "        break\n",
    "\n",
    "    # Check if more than 1 minute has elapsed\n",
    "    # if time.time() - start_time > 60:\n",
    "    #     break\n",
    "print(frame_count)\n",
    "cap.release()  # Release the video capture object\n",
    "result_video.release()  # Release the video writer object\n",
    "cv2.destroyAllWindows()  # Close all the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
