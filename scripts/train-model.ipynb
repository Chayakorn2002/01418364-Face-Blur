{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2ZoXFNMEywt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import glob as gb\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7r6N9axr3AFQ",
    "outputId": "9468557d-87f7-425c-cad5-2ef10273e170"
   },
   "outputs": [],
   "source": [
    "# Define Training dataset\n",
    "train_dir = '../images/train'\n",
    "Train_Data = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    horizontal_flip = True,\n",
    "    rescale = 1 / 255.0,\n",
    ").flow_from_directory(\n",
    "    train_dir, \n",
    "    batch_size = 16, \n",
    "    subset = \"training\", \n",
    "    target_size = (224, 224), # resize image to `224 x 224`\n",
    "    shuffle = False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible classes\n",
    "list(Train_Data.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "D4el7iJX3bxm",
    "outputId": "07e3469e-82df-4e6a-b76c-dc72c806c73d"
   },
   "outputs": [],
   "source": [
    "# Display the first 16 images from the training dataset\n",
    "classes = list(Train_Data.class_indices.keys()) \n",
    "plt.figure(figsize=(30, 30))\n",
    "\n",
    "# Iterate over batches of images and labels in the training dataset\n",
    "for X_batch, y_batch in Train_Data: \n",
    "    # Iterate over the first 16 samples in the batch\n",
    "    for i in range(0, 16):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(X_batch[i])\n",
    "        plt.title(classes[np.where(y_batch[i] == 1)[0][0]])\n",
    "    plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O57aZn2mCUE7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ZeroPadding2D, Convolution2D, MaxPooling2D, Dropout, Flatten, Activation\n",
    "\n",
    "def vgg_face():\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWOBFF1LCUE8"
   },
   "outputs": [],
   "source": [
    "# Model Defined\n",
    "model = vgg_face()\n",
    "model.load_weights('../models/vgg_face_weights.h5') # Load the pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "In27uSIiC3Cx"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Remove the last layer of the model\n",
    "    Commonly used approach in transfer learning scenario\n",
    "      - extracting features from inputted data \n",
    "      - extracting features from the second-to-last layer instead of the final classification layer\n",
    "'''\n",
    "input_layer = model.layers[0].input\n",
    "output_layer = model.layers[-2].output # second-to-last layer\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jvjQN9VZ6pI",
    "outputId": "cab61209-c566-4b14-e482-08f3bfa2fa83"
   },
   "outputs": [],
   "source": [
    "# Extract feature vectors from the training data \n",
    "# By passing the training data to the model's predict function\n",
    "embedding_vector = model.predict(\n",
    "                        Train_Data, # Training data\n",
    "                        steps=len(Train_Data), # Number of steps (batches of samples) to yield from the generator before stopping\n",
    "                        verbose=1 # Verbosity mode : progress bar\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObHJNbBf6zq3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Save the features\n",
    "np.save(\"../dumped_model/features.npy\", embedding_vector)\n",
    "\n",
    "# Save the labels\n",
    "np.save(\"../dumped_model/labels.npy\", Train_Data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKt5Gwa14Uiv"
   },
   "outputs": [],
   "source": [
    "embedding_vector = np.load('features.npy')\n",
    "y_train = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNFTqa6rGCqk"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    embedding_vector, # Features\n",
    "                                    y_train, # Labels\n",
    "                                    test_size=0.1, # 10% of data for testing\n",
    "                                    shuffle=True, # Shuffle the data\n",
    "                                    stratify=y_train, # Same distribution of classes\n",
    "                                    random_state=42\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1gr63m3wuvj"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() # Standardize features by removing the mean and scaling to unit variance\n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nrtdmU4lFCyQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Principal component analysis : Linear dimensionality reduction\n",
    "pca = PCA(n_components=128) \n",
    "X_train = pca.fit_transform(X_train) \n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PvS-75HFC1E",
    "outputId": "de57e46d-8e5b-4e5a-e522-205a3d72c5bc"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Support Vector Classification\n",
    "clf = SVC(\n",
    "    kernel='linear', # Linear kernel\n",
    "    C=2., # Regularization parameter\n",
    "    class_weight='balanced', # Adjust weights inversely proportional to class frequencies\n",
    "    decision_function_shape='ovo', # One-vs-one decision function\n",
    "    probability=True # Enable probability estimates\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_i8IyigFC3-"
   },
   "outputs": [],
   "source": [
    "# Find the classification accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_predict = clf.predict(X_test)\n",
    "print(y_predict[:5])\n",
    "print(y_test[:5])\n",
    "print(f'The Accuracy of VGGFace2 is {accuracy_score(y_test,y_predict)*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "8HekfYdbFhfE",
    "outputId": "7683f426-cb28-457c-fa37-858050c05e09"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_predict)\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(cm,  annot=True, fmt=\"d\" ,cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KXDHQHdiO8TX",
    "outputId": "846f9c3d-391a-4ccc-cc18-997046e6c139"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8JBFkG3M-cr"
   },
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(scaler, '../dumped_model/scaler.joblib') \n",
    "dump(pca, '../dumped_model/pca_model.joblib')\n",
    "dump(clf, '../dumped_model/SVC.joblib') "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Face Recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
